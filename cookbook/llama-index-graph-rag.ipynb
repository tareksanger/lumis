{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tareksanger/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumis.config import config\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import logging\n",
    "import sys\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "\n",
    "\n",
    "# define LLM\n",
    "\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4-turbo\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"  # default is \"nebula\"\n",
    "os.environ[\"NEBULA_ADDRESS\"] = \"127.0.0.1:9669\"\n",
    "\n",
    "space_name = \"stantec\"\n",
    "\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_space(address: str, space_name: str):\n",
    "    from nebula3.gclient.net import ConnectionPool\n",
    "    from nebula3.Config import Config\n",
    "\n",
    "    # Configuration for the connection\n",
    "    config = Config()\n",
    "    config.max_connection_pool_size = 10\n",
    "    # Initialize connection pool\n",
    "    connection_pool = ConnectionPool()\n",
    "    if not connection_pool.init([address.split(\":\")], config):\n",
    "        pp.pprint(\"Failed to initialize connection pool.\")\n",
    "        return\n",
    "\n",
    "    # Connect to the server\n",
    "    session = connection_pool.get_session(\n",
    "        os.environ[\"NEBULA_USER\"], os.environ[\"NEBULA_PASSWORD\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Drop the space\n",
    "        session.execute(f\"DROP SPACE IF EXISTS {space_name}\")\n",
    "\n",
    "    finally:\n",
    "        session.release()\n",
    "        connection_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', '9669')\n"
     ]
    }
   ],
   "source": [
    "delete_space(os.environ[\"NEBULA_ADDRESS\"], space_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespace_if_not_exists(\n",
    "    address: str, namespace_name: str, vid_type=\"FIXED_STRING\", vid_size=256\n",
    "):\n",
    "    from nebula3.gclient.net import ConnectionPool\n",
    "    from nebula3.Config import Config\n",
    "\n",
    "    # Configuration for the connection\n",
    "    config = Config()\n",
    "    config.max_connection_pool_size = 10\n",
    "    # Initialize connection pool\n",
    "    connection_pool = ConnectionPool()\n",
    "    if not connection_pool.init([address], config):\n",
    "        pp.pprint(\"Failed to initialize connection pool.\")\n",
    "        return\n",
    "\n",
    "    # Connect to the server\n",
    "    session = connection_pool.get_session(\n",
    "        os.environ[\"NEBULA_USER\"], os.environ[\"NEBULA_PASSWORD\"]\n",
    "    )\n",
    "    try:\n",
    "        # Determine the vid_type specification\n",
    "        if vid_type == \"FIXED_STRING\":\n",
    "            vid_spec = f\"fixed_string({vid_size})\"\n",
    "        else:\n",
    "            vid_spec = \"int64\"\n",
    "        create_space_command = f\"CREATE SPACE IF NOT EXISTS {namespace_name}(vid_type={vid_spec}, partition_num=1, replica_factor=1)\"\n",
    "        create_space_result = session.execute(create_space_command)\n",
    "        if create_space_result.is_succeeded():\n",
    "            pp.pprint(\n",
    "                [\n",
    "                    f\"Namespace '{namespace_name}' created successfully.\",\n",
    "                    create_space_result.comment(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            pp.pprint([\"Failed to create namespace.\", create_space_result.error_msg()])\n",
    "\n",
    "    finally:\n",
    "        session.release()\n",
    "        connection_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', '9669')\n",
      "[\"Namespace 'stantec' created successfully.\", '']\n"
     ]
    }
   ],
   "source": [
    "create_namespace_if_not_exists(os.environ[\"NEBULA_ADDRESS\"], space_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to get session, cannot set the session space to stantec error: -1005 SpaceNotFound: SpaceName `stantec`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StorageContext\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_stores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnebula\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NebulaGraphStore\n\u001b[0;32m----> 4\u001b[0m graph_store \u001b[38;5;241m=\u001b[39m \u001b[43mNebulaGraphStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspace_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrel_prop_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_prop_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Looks like we might be able to add more storage methods to the storage context\u001b[39;00m\n\u001b[1;32m     12\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(graph_store\u001b[38;5;241m=\u001b[39mgraph_store)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/lib/python3.12/site-packages/llama_index/graph_stores/nebula/base.py:142\u001b[0m, in \u001b[0;36mNebulaGraphStore.__init__\u001b[0;34m(self, session_pool, space_name, edge_types, rel_prop_names, tags, tag_prop_names, include_vid, session_pool_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_pool: Any \u001b[38;5;241m=\u001b[39m session_pool\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_session_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vid_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_vid_type()\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tags \u001b[38;5;241m=\u001b[39m tags \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/lib/python3.12/site-packages/llama_index/graph_stores/nebula/base.py:228\u001b[0m, in \u001b[0;36mNebulaGraphStore.init_session_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m session_pool \u001b[38;5;241m=\u001b[39m SessionPool(\n\u001b[1;32m    221\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEBULA_USER\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    222\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEBULA_PASSWORD\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space_name,\n\u001b[1;32m    224\u001b[0m     [(graphd_host, \u001b[38;5;28mint\u001b[39m(graphd_port))],\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    227\u001b[0m seesion_pool_config \u001b[38;5;241m=\u001b[39m SessionPoolConfig()\n\u001b[0;32m--> 228\u001b[0m \u001b[43msession_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseesion_pool_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_pool \u001b[38;5;241m=\u001b[39m session_pool\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session_pool\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/lib/python3.12/site-packages/nebula3/gclient/net/SessionPool.py:118\u001b[0m, in \u001b[0;36mSessionPool.init\u001b[0;34m(self, configs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# iterate all addresses and create sessions to fullfil the min_size\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configs\u001b[38;5;241m.\u001b[39mmin_size):\n\u001b[0;32m--> 118\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet session failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/lib/python3.12/site-packages/nebula3/gclient/net/SessionPool.py:426\u001b[0m, in \u001b[0;36mSessionPool._new_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m     resp \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space_name))\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mis_succeeded():\n\u001b[0;32m--> 426\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    427\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get session, cannot set the session space to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m error: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    428\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space_name, resp\u001b[38;5;241m.\u001b[39merror_code(), resp\u001b[38;5;241m.\u001b[39merror_msg()\n\u001b[1;32m    429\u001b[0m             )\n\u001b[1;32m    430\u001b[0m         )\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AuthFailedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# if auth failed because of credentials, close the pool\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to get session, cannot set the session space to stantec error: -1005 SpaceNotFound: SpaceName `stantec`"
     ]
    }
   ],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "\n",
    "# Looks like we might be able to add more storage methods to the storage context\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet(None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_store.execute(\"CREATE TAG IF NOT EXISTS entity(name string)\")\n",
    "graph_store.execute(\"CREATE EDGE IF NOT EXISTS relationship(relationship string)\")\n",
    "graph_store.execute(\"CREATE TAG INDEX entity_index ON entity(name(256))\")\n",
    "# CREATE TAG entity(name string);\n",
    "# CREATE EDGE relationship(relationship string);\n",
    "# CREATE TAG INDEX entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core.utils import globals_helper\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "def process_document(document: Document):\n",
    "\n",
    "    words = document.text.split(\" \")\n",
    "    words = [word for word in words]\n",
    "    document.text = \" \".join(words)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(\n",
    "    pages=[\"Stantec\"],\n",
    "    auto_suggest=True,\n",
    ")\n",
    "# documents = [process_document(document) for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# https://docs.llamaindex.ai/en/stable/module_guides/indexing/metadata_extraction/\n",
    "# https://docs.llamaindex.ai/en/stable/module_guides/indexing/vector_store_index/\n",
    "\n",
    "# pipeline = IngestionPipeline(\n",
    "#   storage_context=storage_context,\n",
    "#   settings=Settings,\n",
    "#   transformations=[\n",
    "\n",
    "#   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.858618 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.798494 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Use pipelines for more control over data processing\n",
    "\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=100,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    "    retriever_mode=\"embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    include_text=True,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 04b51dfa-a192-4530-bc0a-f6fa7202b41f: === Growth ===\n",
      "Stantec has 28,000 employees and 400 locations on six continen...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: c180a377-af56-47b0-a1f3-53a53464e305: Between 2008 and 2011, gross revenue increased from $1.4 billion to $1.7 bill...\n",
      "INFO:llama_index.core.indices.knowledge_graph.retrievers:> Querying with idx: 98ef6c4b-3002-4a6d-8b6c-3b4e16991bc3: Staff numbers neared 900 and the firm went public on the Toronto Stock Exchan...\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Can you tell me what resources Stantec has it could utilize for future innovation?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Stantec has a robust set of resources that could be utilized for future '\n",
      " 'innovation, including a global presence with 400 locations across six '\n",
      " 'continents, a diverse workforce of 28,000 employees, and a broad range of '\n",
      " 'services in various sectors such as environmental sciences, landscape '\n",
      " \"architecture, and project economics. Additionally, the company's history of \"\n",
      " 'acquiring over 130 firms since 1994, including significant acquisitions like '\n",
      " 'MWH Global, Inc., provides a wealth of expertise and capabilities in '\n",
      " \"infrastructure and engineering. Stantec's involvement in major projects like \"\n",
      " 'the Panama Canal Expansion and the Stantec Tower also demonstrates its '\n",
      " 'capacity to handle large-scale and complex projects, which could further '\n",
      " 'drive innovation. The leadership under CEO Gord Johnston, who has extensive '\n",
      " 'experience in design and project management, along with his qualifications '\n",
      " 'as a certified project management professional and an Envision '\n",
      " 'Sustainability Professional, positions the company to effectively integrate '\n",
      " 'sustainable and innovative practices into its operations.')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query an already built GraphRAG\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumis-tzzr_5k5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

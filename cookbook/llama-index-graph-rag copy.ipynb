{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tareksanger/Library/Caches/pypoetry/virtualenvs/lumis-tzzr_5k5-py3.12/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumis.config import config\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = config.openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "\n",
    "\n",
    "# define LLM\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "llm = OpenAI(temperature=0, model=\"gpt-4-turbo\")\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEBULA_USER\"] = \"root\"\n",
    "os.environ[\"NEBULA_PASSWORD\"] = \"nebula\"  # default is \"nebula\"\n",
    "os.environ[\"NEBULA_ADDRESS\"] = \"127.0.0.1:9669\"\n",
    "\n",
    "space_name = \"stantec\"\n",
    "\n",
    "edge_types, rel_prop_names = [\"relationship\"], [\n",
    "    \"relationship\"\n",
    "]  # default, could be omit if create from an empty kg\n",
    "tags = [\"entity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_space(address: str, space_name: str):\n",
    "    from nebula3.gclient.net import ConnectionPool\n",
    "    from nebula3.Config import Config\n",
    "\n",
    "    # Configuration for the connection\n",
    "    config = Config()\n",
    "    config.max_connection_pool_size = 10\n",
    "    # Initialize connection pool\n",
    "    connection_pool = ConnectionPool()\n",
    "    if not connection_pool.init([address.split(\":\")], config):\n",
    "        pp.pprint(\"Failed to initialize connection pool.\")\n",
    "        return\n",
    "\n",
    "    # Connect to the server\n",
    "    session = connection_pool.get_session(\n",
    "        os.environ[\"NEBULA_USER\"], os.environ[\"NEBULA_PASSWORD\"]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Drop the space\n",
    "        session.execute(f\"DROP SPACE IF EXISTS {space_name}\")\n",
    "\n",
    "    finally:\n",
    "        session.release()\n",
    "        connection_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', '9669')\n"
     ]
    }
   ],
   "source": [
    "delete_space(os.environ[\"NEBULA_ADDRESS\"], space_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_namespace_if_not_exists(\n",
    "    address: str, namespace_name: str, vid_type=\"FIXED_STRING\", vid_size=256\n",
    "):\n",
    "    from nebula3.gclient.net import ConnectionPool\n",
    "    from nebula3.Config import Config\n",
    "\n",
    "    # Configuration for the connection\n",
    "    config = Config()\n",
    "    config.max_connection_pool_size = 10\n",
    "    # Initialize connection pool\n",
    "    connection_pool = ConnectionPool()\n",
    "    if not connection_pool.init([address.split(':')], config):\n",
    "        pp.pprint(\"Failed to initialize connection pool.\")\n",
    "        return\n",
    "\n",
    "    # Connect to the server\n",
    "    session = connection_pool.get_session(\n",
    "        os.environ[\"NEBULA_USER\"], os.environ[\"NEBULA_PASSWORD\"]\n",
    "    )\n",
    "    try:\n",
    "        # Determine the vid_type specification\n",
    "        if vid_type == \"FIXED_STRING\":\n",
    "            vid_spec = f\"fixed_string({vid_size})\"\n",
    "        else:\n",
    "            vid_spec = \"int64\" \n",
    "        create_space_command = f\"CREATE SPACE IF NOT EXISTS {namespace_name}(vid_type={vid_spec}, partition_num=1, replica_factor=1)\"\n",
    "        create_space_result = session.execute(create_space_command)\n",
    "        if create_space_result.is_succeeded():\n",
    "            pp.pprint([f\"Namespace '{namespace_name}' created successfully.\", create_space_result.comment()])\n",
    "        else:\n",
    "            pp.pprint([\"Failed to create namespace.\", create_space_result.error_msg()])\n",
    "\n",
    "    finally:\n",
    "        session.release()\n",
    "        connection_pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nebula3.logger:Get connection to ('127.0.0.1', '9669')\n",
      "[\"Namespace 'stantec' created successfully.\", '']\n"
     ]
    }
   ],
   "source": [
    "create_namespace_if_not_exists(os.environ[\"NEBULA_ADDRESS\"], space_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.graph_stores.nebula import NebulaGraphStore\n",
    "\n",
    "graph_store = NebulaGraphStore(\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    ")\n",
    "\n",
    "# Looks like we might be able to add more storage methods to the storage context\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet(None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_store.execute(\"CREATE TAG IF NOT EXISTS entity(name string)\")\n",
    "graph_store.execute(\n",
    "    \"CREATE EDGE IF NOT EXISTS relationship(relationship string)\"\n",
    ")\n",
    "graph_store.execute(\"CREATE TAG INDEX entity_index ON entity(name(256))\")\n",
    "# CREATE TAG entity(name string);\n",
    "# CREATE EDGE relationship(relationship string);\n",
    "# CREATE TAG INDEX entity_index ON entity(name(256));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "loader = WikipediaReader()\n",
    "\n",
    "documents = loader.load_data(\n",
    "    pages=[\"Stantec\"], auto_suggest=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.875570 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "# Use pipelines for more control over data processing\n",
    "\n",
    "index = KnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    max_triplets_per_chunk=100,\n",
    "    space_name=space_name,\n",
    "    edge_types=edge_types,\n",
    "    rel_prop_names=rel_prop_names,\n",
    "    tags=tags,\n",
    "    include_embeddings=True,\n",
    "    retriever_mode='embedding'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Company URL\n",
    "\n",
    "url = \"https://www.stantec.com/en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab info from company website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    }
   ],
   "source": [
    "from lumis.knowledge.CompanyInsights import CompanyInsights\n",
    "\n",
    "\n",
    "company_insights = CompanyInsights(root_domain=url)\n",
    "website_documents = company_insights.get_documents()\n",
    "\n",
    "pprint.pprint(len(website_documents))\n",
    "\n",
    "# index = KnowledgeGraphIndex.from_documents(\n",
    "#     website_documents,\n",
    "#     storage_context=storage_context,\n",
    "#     max_triplets_per_chunk=70,\n",
    "#     space_name=space_name,\n",
    "#     edge_types=edge_types,\n",
    "#     rel_prop_names=rel_prop_names,\n",
    "#     tags=tags,\n",
    "#     include_embeddings=True,\n",
    "#     retriever_mode=\"embedding\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import KnowledgeGraphRAGRetriever\n",
    "\n",
    "graph_rag_retriever = KnowledgeGraphRAGRetriever(\n",
    "    storage_context=storage_context,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever=graph_rag_retriever,\n",
    "    response_mode=\"tree_summarize\",\n",
    "    embedding_mode=\"hybrid\",\n",
    "    include_text=True,\n",
    "    similarity_top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "\"\"\"\n",
    "Identify opportunities that leverage Stantec's specific competitive advantages to compete in a market or \n",
    "industry that they don't currently compete in and explain why they are uniquely positioned to do so.\n",
    "\n",
    "Provide your answer in the form of a structured summary. Include a summary of the competitive advantage, \n",
    "financial strengths and weaknesses, and the market or industry that they should enter.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "\n",
    "pprint.pprint(response.source_nodes[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Competitive Advantage Summary:**\n",
       "Stantec has a robust competitive advantage in project management and infrastructure design, as evidenced by their experience in these areas under the leadership of Gord Johnston. Their involvement in diverse projects, including the FEMA Risk Map Production and Technical Services, showcases their capability in handling large-scale and nationwide projects. Additionally, Stantec's global presence, with locations in the United Kingdom and Turkey, and their operations across various regions, position them as a company with significant international reach and operational flexibility.\n",
       "\n",
       "**Financial Strengths and Weaknesses:**\n",
       "While specific financial details are not provided, Stantec’s involvement in large-scale projects and management of diverse projects suggest financial robustness necessary for undertaking substantial investments. Their ability to partner with potential clients and impact communities indicates a strong market position and community trust, which are crucial for financial stability. However, the expansion into new markets or industries could strain resources if not managed with careful financial planning and risk assessment.\n",
       "\n",
       "**Suggested Market or Industry for Entry:**\n",
       "Given Stantec’s expertise in infrastructure and project management, along with their experience in environmental services (as indicated by their project with FEMA), a promising new industry for them could be renewable energy infrastructure. This sector requires robust project management skills and benefits from companies that understand regulatory and environmental challenges. Stantec’s experience in managing diverse and large-scale projects, combined with their global operational capabilities, positions them uniquely to handle the complexities of renewable energy projects, which often span multiple international territories and require careful coordination of technical and environmental considerations.\n",
       "\n",
       "**Rationale for Industry Entry:**\n",
       "The renewable energy sector is growing globally, driven by increasing environmental concerns and the push for sustainable development. Stantec’s existing competencies in infrastructure design and project management, coupled with their commitment to community and environmental well-being, align well with the needs of this industry. Their global presence and ability to collaborate across various regions offer a strategic advantage in navigating the multinational landscape of renewable energy projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query an already built GraphRAG\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumis-tzzr_5k5-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
